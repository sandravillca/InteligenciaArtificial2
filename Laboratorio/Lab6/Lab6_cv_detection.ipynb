{"cells":[{"cell_type":"markdown","metadata":{"id":"5jiB0X4xjK2o"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/048_cv_detection/cv_detection.ipynb)"]},{"cell_type":"markdown","source":["#Laboratorio 6. Detección de objetos con el modelo Sparse R-CNN"],"metadata":{"id":"YFtV9bJT2aDh"}},{"cell_type":"markdown","source":["DE LAS DIFERENTES ARQUITECTURAS QUE EXISTEN PARA HACER DETECCIÓN DE OBJETOS, PODEMOS CATEGORIZARLAS EN 2 GRUPOS:\n","1. DETECTORES DE DOS ETAPAS: TENEMOS UNS PRIMERA ETAPA EN LA QUE UN ALGORITMO (RED NEURONAL U OTRO) NOS PROPONE CAJAS -> \"AQUÍ HAY UN OBJETO, AQUÍ OTRO....\"\\\n","LUEGO HAY UNA SEGUNDA ETAPA QUE SE ENCARGA DE CLASIFICAR LOS OBJETOS QUE HAY DENTRO DE ÉSTAS CAJAS QUE NOS HA PROPUESTO LA PRIMERA ETAPA.\\\n","-ÉSTE TIPO DE ALGORITMOS SON LOS QUE TIENEN MEJOR PRECISIÓN, MÁS ACIERTAN. SIN EMBARGO SON BASTANTE LENTOS, PESADOS DE CALCULAR.\\\n","-POR TANTO, NO SE UTILIZAN PARA APLICACIONES EN TIEMPO REAL.\n","2. DTECTORES DE UNA ETAPA\\\n","EN UNA SOLA ETAPA NOS DAN YA LAS CAJAS Y LAS CLASIFICACIONES DENTRO DE ELLAS.\\\n","-SON ALGORITMOS MÁS RÁPIDOS, SE PUEDEN UTILIZAR PARA APLICACIONES EN TIEMPO REAL PERO TIENEN MENOS PRECISIÓN QUE LOS DE 2 ETAPAS."],"metadata":{"id":"vMaDH9pz3NzM"}},{"cell_type":"markdown","source":["###Actualizar pip"],"metadata":{"id":"YpLCT9xU1fVT"}},{"cell_type":"code","source":["!pip install --upgrade pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OdTaQai1NLS","executionInfo":{"status":"ok","timestamp":1730684457260,"user_tz":240,"elapsed":5111,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}},"outputId":"9efe0808-6d44-473e-b60d-b19eeab95cf5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n","Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-24.3.1\n"]}]},{"cell_type":"markdown","source":["###Instalar dependencias"],"metadata":{"id":"O8zRxbYg1kqE"}},{"cell_type":"code","source":["!apt-get install -y gcc g++  # Necesario para compilar algunas bibliotecas\n","!pip install cython"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCTkrHMS1U_Q","executionInfo":{"status":"ok","timestamp":1730684568012,"user_tz":240,"elapsed":5771,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}},"outputId":"c4954e3b-8367-4e1c-d6e0-21d3a3134f24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","g++ is already the newest version (4:11.2.0-1ubuntu1).\n","g++ set to manually installed.\n","gcc is already the newest version (4:11.2.0-1ubuntu1).\n","gcc set to manually installed.\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.11)\n"]}]},{"cell_type":"markdown","source":["###Clonar el repositorio de MMDetection"],"metadata":{"id":"bgOxlaGr1xCR"}},{"cell_type":"code","source":["!git clone https://github.com/open-mmlab/mmdetection.git\n","%cd mmdetection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1egFYxQ12at","executionInfo":{"status":"ok","timestamp":1730684646335,"user_tz":240,"elapsed":5911,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}},"outputId":"bede207d-9ba4-4744-c102-d5b513165bf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mmdetection'...\n","remote: Enumerating objects: 38023, done.\u001b[K\n","remote: Total 38023 (delta 0), reused 0 (delta 0), pack-reused 38023 (from 1)\u001b[K\n","Receiving objects: 100% (38023/38023), 63.25 MiB | 22.84 MiB/s, done.\n","Resolving deltas: 100% (26223/26223), done.\n","/content/mmdetection\n"]}]},{"cell_type":"markdown","source":["###Instalar MMDetection"],"metadata":{"id":"nsJ8I2Vy2F8k"}},{"cell_type":"code","source":["!pip install -r requirements/build.txt  # Instalar requisitos de construcción\n","!pip install -v -e .  # Instalar MMDetection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PYYBxg62JCP","executionInfo":{"status":"ok","timestamp":1730684730374,"user_tz":240,"elapsed":14409,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}},"outputId":"19f61b11-497e-44cb-eb8b-3957fa0b55f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements/build.txt (line 2)) (3.0.11)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements/build.txt (line 3)) (1.26.4)\n","Using pip 24.3.1 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n","Obtaining file:///content/mmdetection\n","  Running command python setup.py egg_info\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info\n","  writing /tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  warning: no files found matching 'mmdet/VERSION'\n","  warning: no files found matching 'mmdet/.mim/model-index.yml'\n","  warning: no files found matching 'mmdet/.mim/dataset-index.yml'\n","  warning: no files found matching 'mmdet/.mim/demo/*/*'\n","  warning: no files found matching '*.py' under directory 'mmdet/.mim/configs'\n","  warning: no files found matching '*.yml' under directory 'mmdet/.mim/configs'\n","  warning: no files found matching '*.sh' under directory 'mmdet/.mim/tools'\n","  warning: no files found matching '*.py' under directory 'mmdet/.mim/tools'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-pip-egg-info-lgak7gp2/mmdet.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.26.4)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (2.0.8)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.13.1)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (2.0.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.16.0)\n","Collecting terminaltables (from mmdet==3.3.0)\n","  Obtaining dependency information for terminaltables from https://files.pythonhosted.org/packages/c4/fb/ea621e0a19733e01fe4005d46087d383693c0f4a8f824b47d8d4122c87e0/terminaltables-3.1.10-py2.py3-none-any.whl.metadata\n","  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (4.66.6)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (2.8.2)\n","Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n","Installing collected packages: terminaltables, mmdet\n","\u001b[33m  DEPRECATION: Legacy editable install of mmdet==3.3.0 from file:///content/mmdetection (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n","\u001b[0m  Running setup.py develop for mmdet\n","    Running command python setup.py develop\n","    running develop\n","    /usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n","    !!\n","\n","            ********************************************************************************\n","            Please avoid running ``setup.py`` and ``easy_install``.\n","            Instead, use pypa/build, pypa/installer or other\n","            standards-based tools.\n","\n","            See https://github.com/pypa/setuptools/issues/917 for details.\n","            ********************************************************************************\n","\n","    !!\n","      easy_install.initialize_options(self)\n","    /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","    !!\n","\n","            ********************************************************************************\n","            Please avoid running ``setup.py`` directly.\n","            Instead, use pypa/build, pypa/installer or other\n","            standards-based tools.\n","\n","            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","            ********************************************************************************\n","\n","    !!\n","      self.initialize_options()\n","    running egg_info\n","    creating mmdet.egg-info\n","    writing mmdet.egg-info/PKG-INFO\n","    writing dependency_links to mmdet.egg-info/dependency_links.txt\n","    writing requirements to mmdet.egg-info/requires.txt\n","    writing top-level names to mmdet.egg-info/top_level.txt\n","    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n","    reading manifest file 'mmdet.egg-info/SOURCES.txt'\n","    reading manifest template 'MANIFEST.in'\n","    warning: no files found matching 'mmdet/VERSION'\n","    warning: no files found matching 'mmdet/.mim/demo/*/*'\n","    adding license file 'LICENSE'\n","    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n","    /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","      warnings.warn(msg.format('we could not find ninja.'))\n","    running build_ext\n","    Creating /usr/local/lib/python3.10/dist-packages/mmdet.egg-link (link to .)\n","    Adding mmdet 3.3.0 to easy-install.pth file\n","\n","    Installed /content/mmdetection\n","Successfully installed mmdet terminaltables-3.1.10\n"]}]},{"cell_type":"markdown","source":["###Instalar MMCV"],"metadata":{"id":"_vA2U0uv28c1"}},{"cell_type":"code","source":["!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.5.0/index.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgNjFluC8MV-","executionInfo":{"status":"ok","timestamp":1730689184130,"user_tz":240,"elapsed":2900171,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}},"outputId":"abd47592-74dc-494a-d093-86544e1be52f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.5.0/index.html\n","Collecting mmcv-full\n","  Using cached mmcv-full-1.7.2.tar.gz (607 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting addict (from mmcv-full)\n","  Using cached addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (24.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (10.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (6.0.2)\n","Collecting yapf (from mmcv-full)\n","  Using cached yapf-0.40.2-py3-none-any.whl.metadata (45 kB)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (8.5.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (4.3.6)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (2.0.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full) (3.20.2)\n","Using cached addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Using cached yapf-0.40.2-py3-none-any.whl (254 kB)\n","Building wheels for collected packages: mmcv-full\n","  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mmcv-full: filename=mmcv_full-1.7.2-cp310-cp310-linux_x86_64.whl size=32414390 sha256=70ec3c1d5810d35119ad81dc88376bf92b1d25f7b644252278c985429b07d5e6\n","  Stored in directory: /root/.cache/pip/wheels/4e/10/0a/78fbabe3d28cc25866432d4ecd6c9b124b8f0a6f546974bb7e\n","Successfully built mmcv-full\n","Installing collected packages: addict, yapf, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.7.2 yapf-0.40.2\n"]}]},{"cell_type":"code","source":["!pip install mmengine"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xwm3dR6iLrCW","executionInfo":{"status":"ok","timestamp":1730690341025,"user_tz":240,"elapsed":3030,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}},"outputId":"9182960b-8989-4e1c-850c-c697e7d0916e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mmengine\n","  Downloading mmengine-0.10.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.26.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.9.3)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.5.0)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmengine) (0.40.2)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.10.0.84)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.18.0)\n","Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (4.12.2)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (8.5.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (4.3.6)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.20.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n","Downloading mmengine-0.10.5-py3-none-any.whl (452 kB)\n","Installing collected packages: mmengine\n","Successfully installed mmengine-0.10.5\n"]}]},{"cell_type":"markdown","source":["###Verificar la instalación"],"metadata":{"id":"HfT2KUuiLAQP"}},{"cell_type":"code","source":["import mmdet\n","print(mmdet.__version__)  # Deberías ver la versión instalada"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"NK4-RxyTLCvI","executionInfo":{"status":"error","timestamp":1730690347144,"user_tz":240,"elapsed":895,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"}},"outputId":"c9e312e0-792e-419b-b5c8-b4fd418cdea2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"MMCV==1.7.2 is used but incompatible. Please install mmcv>=2.0.0rc4, <2.2.0.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-ac2fb501a387>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Deberías ver la versión instalada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/mmdetection/mmdet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m assert (mmcv_version >= digit_version(mmcv_minimum_version)\n\u001b[0;32m---> 17\u001b[0;31m         and mmcv_version < digit_version(mmcv_maximum_version)), \\\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;34mf'MMCV=={mmcv.__version__} is used but incompatible. '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34mf'Please install mmcv>={mmcv_minimum_version}, <{mmcv_maximum_version}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: MMCV==1.7.2 is used but incompatible. Please install mmcv>=2.0.0rc4, <2.2.0."]}]},{"cell_type":"markdown","metadata":{"id":"a144xmMdjK2t"},"source":["## Dataset Plantas\n","\n","Vamos a ver como podemos utilizar el modelo `Faster R-CNN` disponible en `torchvision` para generar detecciones. En primer lugar vamos a utilizar el mismo dataset que hemos usado en los vídeos anteriores, el dataset `VOC` (el modelo `Faster R-CNN` de `torchvision` está entrenado en el dataset `COCO`)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":802,"status":"ok","timestamp":1730686152254,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"JPetjpfUjK2u","outputId":"49ef1ebb-28bf-4fd1-82e6-25e8dfc7076d"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.5.0+cu121\n"]},{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["import torch\n","#print(torch.__version__)\n","import torchvision\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","source":["#Colocar path\n","train = Plantas('./data', download=True)\n","len(train)"],"metadata":{"id":"dy1PhnjD4VQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train[0])"],"metadata":{"id":"Dg3PmDhI4azt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vrj4ziAPjK2v"},"outputs":[],"source":["classes = [\"background\",\n","            \"laurel\",\n","            \"limon\",\n","            \"membrillo\",\n","            \"olivo\",\n","            \"papaya\",\n","            \"molle\",\n","            \"llanten\",\n","            \"naranja\",\n","            \"cmaracuya\",\n","            \"guayaba\",\n","            \"aloevera\",\n","            \"cedron\",\n","            \"floripondio\",\n","            \"higuera\",\n","            \"nispero\",\n","            \"amorseco\",\n","            \"boldo\",\n","            \"perejil\",\n","            \"charanguillo\",\n","            \"ortiga\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VD_c4boYjK2w"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import matplotlib.patheffects as PathEffects\n","import random\n","\n","def get_sample(ix):\n","  img, label = train[ix]\n","  # print(\"+++\"*10)\n","  # print(img)\n","  # print(\"...\"*10)\n","  # print(label)\n","  # print(\"+++\"*10)\n","  img_np = np.array(img)\n","  anns = label['annotation']['object']\n","  if type(anns) is not list:\n","    anns = [anns]\n","  labels = np.array([voc_classes.index(ann['name']) for ann in anns])\n","  bbs = [ann['bndbox'] for ann in anns]\n","  bbs = np.array([[int(bb['xmin']), int(bb['ymin']),int(bb['xmax'])-int(bb['xmin']),int(bb['ymax'])-int(bb['ymin'])] for bb in bbs])\n","  anns = (labels, bbs)\n","  return img_np, anns\n","\n","# def plot_anns(img, anns, ax=None, bg=-1, classes=voc_classes):\n","#   # anns is a tuple with (labels, bbs)\n","#   # bbs is an array of bounding boxes in format [x_min, y_min, width, height]\n","#   # labels is an array containing the label\n","#   if not ax:\n","#     fig, ax = plt.subplots(figsize=(10, 6))\n","#   ax.imshow(img)\n","#   labels, bbs = anns\n","#   for lab, bb in zip(labels, bbs):\n","#     if bg == -1 or lab != bg:\n","#       x, y, w, h = bb\n","#       rect = mpatches.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=2)\n","#       text = ax.text(x, y - 10, classes[lab], {'color': 'red'})\n","#       text.set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n","#       ax.add_patch(rect)\n","\n","def plot_anns(img, anns, ax=None, bg=-1, classes=voc_classes):\n","  # anns is a tuple with (labels, bbs)\n","  # bbs is an array of bounding boxes in format [x_min, y_min, width, height]\n","  # labels is an array containing the label\n","  if not ax:\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","  ax.imshow(img)\n","  labels, bbs = anns\n","  for lab, bb in zip(labels, bbs):\n","    if bg == -1 or lab != bg:\n","      bb = torch.tensor(bb)\n","      x, y, w, h = bb.detach().numpy()\n","      rect = mpatches.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=2)\n","      text = ax.text(x, y - 10, classes[lab], {'color': 'red'})\n","      text.set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n","      ax.add_patch(rect)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1730683683647,"user":{"displayName":"Sandra Villca","userId":"10389606573201869473"},"user_tz":240},"id":"pGNX5VKdCeum","outputId":"2856c8c1-eb34-4d21-aa23-1d674d16c9b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["(333, 500, 3)\n","----------------------------------------\n","(array([9]), array([[ 90,  74, 192, 230]]))\n"]}],"source":["img_np, anns = get_sample(3133)\n","print(img_np.shape)\n","print(\"--\"*20)\n","print(anns)"]},{"cell_type":"code","source":["r, c = 3, 4\n","fig = plt.figure(figsize=(4*c, 4*r))\n","for _r in range(r):\n","    for _c in range(c):\n","        ax = plt.subplot(r, c, _r*c + _c + 1)\n","        ix = random.randint(0, len(train)-1)\n","        img_np, anns = get_sample(ix)\n","        plot_anns(img_np, anns, ax)\n","        plt.axis(\"off\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"JhKSaaeN5eVX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EICHZZi6jK2w"},"source":["###Descargar el modelo entrenado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6385,"status":"ok","timestamp":1714142261949,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"u3BAhzJJjK2x","outputId":"f4b709eb-3236-4934-d44f-1c7263656f33"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:02<00:00, 70.3MB/s]\n"]},{"data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-3): 4 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n","    )\n","  )\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model"]},{"cell_type":"markdown","metadata":{"id":"hA_EXk1kjK2x"},"source":["Siguiendo la documentación, podemos usar este modelo en inferencia pasándole una lista de imágenes normalizadas entre 0-1 con las dimensiones `[C, H, W]` (pueden ser imágenes de diferente tamaño, el modelo ya se encarga del *resize*)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1714142261950,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"zaEMurraPCwb","outputId":"3d3580f0-6bf4-42eb-865a-50427b084c26"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[193 215 229]\n","  [193 215 229]\n","  [194 215 232]\n","  ...\n","  [228 243 246]\n","  [228 243 246]\n","  [228 243 246]]\n","\n"," [[193 215 229]\n","  [193 215 229]\n","  [194 215 232]\n","  ...\n","  [228 243 246]\n","  [228 243 246]\n","  [226 244 246]]\n","\n"," [[194 216 230]\n","  [193 215 229]\n","  [194 215 232]\n","  ...\n","  [229 244 247]\n","  [227 245 247]\n","  [227 245 247]]\n","\n"," ...\n","\n"," [[146 130 117]\n","  [147 131 118]\n","  [146 130 117]\n","  ...\n","  [123 110 102]\n","  [125 112 104]\n","  [119 106  98]]\n","\n"," [[145 131 118]\n","  [142 128 115]\n","  [137 123 110]\n","  ...\n","  [127 115 103]\n","  [131 119 107]\n","  [129 117 105]]\n","\n"," [[142 130 116]\n","  [141 129 115]\n","  [135 123 109]\n","  ...\n","  [128 116 102]\n","  [126 114 100]\n","  [129 117 103]]] (array([1]), array([[ 39, 119, 454, 133]]))\n"]}],"source":["img_np, anns = get_sample(4445)\n","print(img_np, anns)"]},{"cell_type":"code","source":["plot_anns(img_np, anns)\n","plt.show()"],"metadata":{"id":"_rVar9h45wKC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MODO EVALUACIÓN:\\\n","-PASAMOS UNA LISTA DE IMÁGENES, ÉSTAS IMÁGENES TIENEN QUE ESTAR NORMALIZADAS, LA PRIMERA DIMENSIÓN TIENE QUE SER LA DE LOS CANALES (COLOR) -> permute()\\\n","-TODO ESO LE PASAMOS AL MODELO PARA QUE NOS DE LOS OUTPUTS\\\n","-VISUALIZACIÓN DE OUTPUTS: TENEMOS UNA LISTA Y CADA ELEMENTO DE ÉSTA LISTA ES UN DICT. EN ÉSTE CASO LE HEMOS DADO SOLO UNA IMAGEN Y SÓLO TENEMOS UN DICT."],"metadata":{"id":"EcVVTOukFZNx"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714142261950,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"RujlSmNIjK2x","outputId":"ab8a45e1-4a27-4787-fddb-59333ab48cd8"},"outputs":[{"data":{"text/plain":["[{'boxes': tensor([[ 38.9765, 123.2571, 463.2631, 244.7916],\n","          [394.6673, 239.3306, 417.8829, 248.7579],\n","          [ 83.8890, 211.9992,  97.7212, 245.2696],\n","          [391.7524, 240.2934, 407.5306, 248.3502],\n","          [297.7431, 236.6284, 325.2031, 250.0018],\n","          [ 33.2589, 174.6996, 368.3978, 247.6585],\n","          [297.8233, 236.4347, 324.7085, 249.9443],\n","          [ 88.0805, 211.7508,  96.9347, 233.4872],\n","          [209.9664, 119.5987, 489.9711, 232.0793],\n","          [276.2681, 239.4820, 298.6529, 247.7382],\n","          [  1.0193, 227.8070,  24.9193, 240.9534],\n","          [ 76.8103, 229.2830,  82.8956, 246.1568],\n","          [  9.1523, 234.0433,  16.6872, 241.9108],\n","          [268.0753, 238.7643, 301.0202, 249.1797],\n","          [392.7399, 238.6301, 419.9506, 249.2913]], grad_fn=<StackBackward0>),\n","  'labels': tensor([ 5,  3,  1,  3,  3,  5,  8,  1,  5,  3, 15,  1, 11,  8,  8]),\n","  'scores': tensor([0.9950, 0.9116, 0.8834, 0.5434, 0.3926, 0.3855, 0.3645, 0.2069, 0.1535,\n","          0.1354, 0.0943, 0.0934, 0.0575, 0.0574, 0.0523],\n","         grad_fn=<IndexBackward0>)}]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","outputs = model([torch.tensor(img_np / 255.).permute(2,0,1).float()])\n","outputs"]},{"cell_type":"markdown","metadata":{"id":"ISNED14DjK2y"},"source":["A la salida recibimos una lista con las detecciones de cada imagen (en nuestro caso solo una). Cada elemento de la lista es un `dict` con las cajas, etiquetas y las probabilidades asignadas a cada objeto detectado (que podemos filtrar para quedarnos, por ejemplo, con aquellas detecciones con probabilidad superior a un cierto valor). Es importante recordar que estas etiquetas corresponden al dataset `COCO`."]},{"cell_type":"markdown","source":["-EL PRIMER CAMPO ES EL DE BOXES\\\n","-LUEGO TENEMOS LABELS QUE SON LAS ETIQUETAS\\\n","-Y LOS SCORES QUE SERÍA LA PROBABILIDAD ASIGNADA A CADA UNA DE ÉSTAS ETIQUETAS.\\\n","-EN BOXES TENEMOS UNA LISTA CON TODAS LAS CAJAS QUE HA DETECTADO DENTRO DE ESA IMAGEN PERO TENÍAMOS SÓLO UNA -> UN AVIÓN; POR QUÉ NOS HA DADO TANTAS?\\\n","-PORQUE PUEDE DETECTAR MUCHAS COSAS, ALGUNAS BIEN, ALGUNAS MAL. PARA ELLO HAY QUE VENIR A LOS SCORES: MUCHOS DE ELLOS TIENEN VALORES MUY BAJOS, PODEMOS FILTRAR Y DECIR \"DAME SÓLO LOS QUE TENGAN UNA PROBABILIDAD MÁS GRANDE AL 90 POR CIENTO POR EJEMPLO\".\\\n","-EN ÉSTE CASO, VOY A ELEGIR LA PRIMERA QUE TIENE LA ETIQUETA 5 Y\\\n","OJO-> ÉSTA ETIQUETA CORRESPONDE AL DATASET CON EL QUE FUE ENTRENADA ESTA RED ORIGINALMENTE QUE NO ES EL MISMO.\\\n","-ESTAMOS DANDO IMÁGENES DEL DATASET VOC PERO ÉSTA RED FUE ENTRENADA CON EL DATASET COCO QUE TIENE 90 CLASES -> VER LA LISTA ABAJO: 5 ES EL airplane:\n"],"metadata":{"id":"M1JgY2I5HGvY"}},{"cell_type":"markdown","source":[],"metadata":{"id":"deSGkTlj6Pih"}},{"cell_type":"markdown","source":["####FUNCIÓN predict()\n","-BÁSICAMENTE SACA TODAS ÉSTAS CAJAS Y PERMITE VISUALIZAR.\\\n","-PUEDES EJECUTAR ESTA CELDA MUCHAS VECES CON DIFERENTES IMÁGENES Y VER QUE TE DA.\\\n","-DATASET COCO: TIENE MUCHAS MÁS CLASES QUE EL DATASET VOC. SI COMPARAS LAS DETECCIONES QUE TE DA CON LAS ORIGINALES, VERÁS QUE HAY MUCHOS OBJETOS QUE DETECTA BIEN PERO QUE NO ESTABAN EN EL DATASET ORIGINAL.\n","-EN EL CÓDIGO DE ABAJO, ME ESTOY QUEDANDO CON TODAS LAS DETECCIONES QUE TENGAN UNA PROBABILIDAD MAYOR AL 80%.\\\n","threshold=0.8  (zrésh hold)\\\n","ÉSTE ES UN HIPERPARÁMETRO CON EL QUE TIENES QUE JUGAR PARA VER CUÁL FUNCIONA MEJOR.\n"],"metadata":{"id":"iF_XErseJJ12"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAHB_lGkjK2z"},"outputs":[],"source":["def predict(img, threshold=0.8):\n","\n","    model.eval()\n","    outputs = model([torch.tensor(img_np / 255.).permute(2,0,1).float()])\n","    # nos quedamos con la primera detección\n","    bb = outputs[0]['boxes'][0].long().tolist()\n","    bbs = [[bb[0], bb[1], bb[2]-bb[0], bb[3]-bb[1]] for o in outputs for bb, score in zip(o['boxes'], o['scores']) if score > threshold]\n","    labels = [lab for o in outputs for lab, score in zip(o['labels'], o['scores']) if score > threshold]\n","\n","    return labels, bbs\n"]},{"cell_type":"code","source":["ix = random.randint(0, len(train)-1)\n","img_np, anns = get_sample(ix)\n","plot_anns(img_np, anns)\n","plt.show()"],"metadata":{"id":"4_g42WoA6T0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["anns = predict(img_np)\n","#plot_anns(img_np, anns, classes=COCO_INSTANCE_CATEGORY_NAMES)\n","plot_anns(img_np, anns, classes=SPARSE_INSTANCE_CATEGORY_NAMES)\n","plt.show()"],"metadata":{"id":"DP12Vmf66XBp"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/048_cv_detection/cv_detection.ipynb","timestamp":1621577482254}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}